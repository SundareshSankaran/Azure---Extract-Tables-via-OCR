{"type":"code","name":"OCR - Azure Document Intelligence.step","displayName":"OCR - Azure Document Intelligence.step","description":"","templates":{"SAS":"proc python restart;\nsubmit;\n# Imports\ntry:\n    from azure.core.credentials import AzureKeyCredential\n    from azure.ai.documentintelligence import DocumentIntelligenceClient\n    from azure.ai.documentintelligence.models import DocumentAnalysisFeature\n    from azure.ai.documentintelligence.models._models import AnalyzeResult, AnalyzeDocumentRequest\n\n    import pandas as pd\n    import numpy as np\n    import functools\n    import requests\n    import threading\n    import json\n    import io\n    import re\n    import os\n    import uuid\n    from urllib.parse import urlparse\n    from datetime import datetime\nexcept ImportError as e:\n    SAS.logMessage(f'ImportError - {e}. Please install the required packages!', 'error')\n    exit()\n\n################### DEFINE PARAMETERS ###################\n# azure credentials & container\nazure_key = str(SAS.symget(\"azure_key\"))\nazure_endpoint = str(SAS.symget(\"azure_endpoint\"))\nlocal_ocr = bool(SAS.symget(\"local_ocr\"))                             \t# whether to use a locally deployed document intelligence container, default = False\nlocal_ocr_endpoint = str(SAS.symget(\"local_ocr_endpoint\")) \t\t\t\t# endpoint of the locally deployed document intelligence container\n\nSERVICE_VERSION = '4.0'                         \t\t\t\t\t\t# 4.0 is in preview. Local containers are only supported in 3.0 (GA) thus far\nAPI_VERSION = '2023-10-31-preview'              \t\t\t\t\t\t# default: '2023-10-31-preview'- to lock the API version, in case breaking change are introduced\n\n# general\nocr_type = str(SAS.symget(\"ocr_type\"))                          \t\t# type of OCR: text, form, query, table\ninput_type = str(SAS.symget(\"input_type\"))                       \t\t# type of input: file, url \ninput_mode = str(SAS.symget(\"input_mode\"))                        \t\t# single or batch\nfile_path = str(SAS.symget(\"file_path\"))  \t\t\t\t\t\t\t\t# path to a (single) file\nfile_url = str(SAS.symget(\"file_url\")) \ninput_table_name = str(SAS.symget(\"input_table_name\"))                  # name of table containing the file paths\npath_column = str(SAS.symget(\"path_column\"))                            # column that contains the file path\noutput_status_table = bool(SAS.symget(\"output_status_table\"))           # whether to output the status table\n\n# advanced\nlocale = str(SAS.symget(\"ocr_locale\"))                               \t# optional, language of the document. Support-list: https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/language-support-ocr?view=doc-intel-4.0.0&tabs=read-hand%2Clayout-print%2Cgeneral\nn_threads = int(SAS.symget(\"n_threads\"))                             \t# number of threads to use for parallel processing\nn_con_retry = int(SAS.symget(\"n_con_retry\"))                            # number of retries if connection fails\nretry_delay = int(SAS.symget(\"retry_delay\"))                            # delay between retries\nsave_json = bool(SAS.symget(\"save_json\"))                         \t\t# whether to save the json output\njson_output_folder = str(SAS.symget(\"json_output_folder\"))              # folder to save the json output\n\n# for text extraction\ntext_granularity = str(SAS.symget(\"text_granularity\"))               \t# level of detail: word, line, paragraph, page, document\nmodel_id = str(SAS.symget(\"model_id\"))                \t\t\t\t\t# Has cost implications. Layout more expensive but allows for more features: prebuilt-read, prebuilt-layout\nextract_pragraph_roles = bool(SAS.symget(\"extract_pragraph_roles\"))\n\n# for query extraction\nquery_fields = str(SAS.symget(\"ocr_query_fields\"))          \t\t\t\t# string containing comma separated keys to extract\nquery_exclude_metadata = bool(SAS.symget(\"query_exclude_metadata\"))     # if excluded, the resulting table will contain a column per query field (doesn't support ocr metadata like bounding boxes)\n\n# for table extraction\ntable_output_format = str(SAS.symget(\"table_output_format\"))            # how the tables should be returned: map, reference*, table** *reference requires a cas\ntable_output_library = str(SAS.symget(\"table_output_library\"))          # caslib to store the table (only relevant if table_output_format = 'reference')\nselect_table = bool(SAS.symget(\"select_table\"))                      \t# whether to select a specific table or all tables (only relevant if table_output_format = 'reference')\ntable_selection_method = str(SAS.symget(\"table_selection_method\"))      # how to select the table: size, index (only relevant if table_output_format = 'reference' and selected_table = True)\ntable_selection_idx = int(SAS.symget(\"table_selection_idx\"))            # index of the table to extract (only relevant if table_output_format = 'table')\n\n##################### HELPER FUNCTIONS #####################\ndef retry_on_endpoint_connection_error(max_retries=3, delay=2):\n    \"\"\"\n    This is a decorator function that allows a function to retry execution when an EndpointConnectionError occurs.\n\n    Parameters:\n    -----------\n    max_retries (int): \n        The maximum number of retries if an EndpointConnectionError occurs. Default is 3.\n    delay (int): \n        The delay (in seconds) between retries. Default is 2.\n\n    Returns:\n    wrapper function: \n        The decorated function that includes retry logic.\n    \"\"\"\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            retries = 0\n            while retries < max_retries:\n                try:\n                    return func(*args, **kwargs)\n                    \"\"\" except EndpointConnectionError as e:\n                        SAS.logMessage(f'Retrying due to EndpointConnectionError: {e}')\n                        retries += 1\n                        time.sleep(delay) \"\"\"\n                except Exception as e:\n                    raise e  # Let other exceptions be handled by the utility class\n\n            if retries == max_retries:\n                #SAS.logMessage(f\"Max retries ({max_retries}) reached. Unable to complete operation.\", 'warning')\n                raise RuntimeError(\"Max retries to contact Azure endpoint reached. Unable to complete operation.\")\n        return wrapper\n\n    return decorator\n\ndef prepare_query(query_list: str):\n    \"\"\" Parse the query string to a list of query keys\n\n    Parameters:\n    -----------\n    query_list:\n        str: comma separated string of queries\n    \n    Returns:\n    --------\n    query_list:\n        list(str): list of queries\n    \"\"\"\n    query_list = query_list.split(',')\n    query_list = [q.strip() for q in query_list] # remove leading and trailing whitespace\n    query_list = [q.replace(' ', '_') if ' ' in q else q for q in query_list] # replace spaces with underscores\n        \n    \n    # check if query string is regex compatible (azure document intelligence requirement)\n    for q in query_list:\n        try:\n            re.compile(q)\n        except re.error:\n            ValueError(f'Query string {q} is not regex compatible!')\n        \n    return query_list\n\n\n    \"\"\" Check if a url is valid\n\n    Parameters:\n    -----------\n    url:\n        str: url to check\n    \n    Returns:\n    --------\n    bool: True if url is valid, False otherwise\n    \"\"\"\n    try:\n        result = urlparse(url)\n        return all([result.scheme, result.netloc])\n    except ValueError:\n        return False\n\n###################### OCR STRATEGIES #####################\n# parent class for the OCR strategies\nclass OCRStrategy:\n    \"\"\" Base class for the OCR strategies \"\"\"\n    def __init__(self, ocr_client, kwargs):\n        self.ocr_client = ocr_client\n        self.kwargs = kwargs\n\n    def parse_ocr_result(self, result) -> pd.DataFrame:\n        pass\n\n    def analyze_document(self, document) -> pd.DataFrame:\n        pass\n\n# implemented OCR strategies\nclass ExtractText(OCRStrategy): \n    def __init__(self, ocr_client, kwargs):\n        self.ocr_client = ocr_client\n        self.local_ocr = kwargs.get('local_ocr', False)\n        self.input_type = kwargs.get('input_type', 'file')\n        self.text_granularity = kwargs.get('text_granularity', 'line')\n        self.file_location = kwargs.get('file_location', 'local')\n        self.locale = kwargs.get('locale', '')\n        self.model_id = kwargs.get('model_id', 'prebuilt-read')\n\n        if self.local_ocr:\n            self.endpoint = kwargs.get('endpoint', 'http://localhost:5000')\n\n    def parse_ocr_result(self,result) -> pd.DataFrame:\n        parsed_result = pd.DataFrame()\n\n        # set the text granularity\n        level = self.text_granularity\n        if (level.upper() == 'PAGE'):\n            self.text_granularity = \"LINE\"\n        else:\n            self.text_granularity = level.upper()\n        \n        if self.text_granularity == \"DOCUMENT\":\n            ocr_data = []\n            \n            # check if the document contains handwriting\n            try:\n                contains_handwriting = result['styles'][0]['isHandwritten']\n            except:\n                contains_handwriting = False\n\n            document_info = {\n                \"text\": result['content'],\n                \"contains_handwriting\": contains_handwriting,\n                }\n            ocr_data.append(document_info)\n            df = pd.DataFrame(ocr_data)\n            parsed_result = pd.concat([parsed_result, df], ignore_index=True)\n\n        elif self.text_granularity == \"PARAGRAPH\":\n            ocr_data = []\n            for paragraph_idx, paragraph in enumerate(result['paragraphs']):\n                x1, y1, x2, y2, x3, y3, x4, y4 = paragraph['boundingRegions'][0]['polygon']\n\n                try: \n                    role = paragraph['role']\n                except:\n                    role = ''\n\n                paragrpah_info = {\n                    \"page\": paragraph['boundingRegions'][0]['pageNumber'],\n                    \"paragraph\": paragraph_idx,\n                    \"role\": role,\n                    \"text\": paragraph['content'], \n                    \"bb_x1\": x1,\n                    \"bb_y1\": y1,\n                    \"bb_x2\": x2,\n                    \"bb_y2\": y2,\n                    \"bb_x3\": x3,\n                    \"bb_y3\": y3,\n                    \"bb_x4\": x4,\n                    \"bb_y4\": y4,\n                    \"offset\": paragraph['spans'][0]['offset'],\n                    \"length\": paragraph['spans'][0]['length'],\n                }\n                \n                ocr_data.append(paragrpah_info)\n            df = pd.DataFrame(ocr_data)\n            parsed_result = pd.concat([parsed_result, df], ignore_index=True)\n        else:\n            for page in result['pages']:\n                ocr_data = []\n                \n                # to calculate the average confidence\n                if self.text_granularity != \"WORD\":\n                    word_confidences = [word['confidence'] for word in page['words']]\n                    total_confidence = sum(word_confidences)\n                    total_words = len(word_confidences)\n                    average_confidence = total_confidence / total_words if total_words > 0 else 0\n\n                # extraction on line level\n                if self.text_granularity == \"LINE\":\n                    for line_idx, line in enumerate(page['lines']):\n                        x1, y1, x2, y2, x3, y3, x4, y4 = line['polygon']\n\n                        line_info = {\n                            \"page\": page['pageNumber'],\n                            \"line\": line_idx,\n                            \"text\": line['content'],\n                            \"bb_x1\": x1,\n                            \"bb_y1\": y1,\n                            \"bb_x2\": x2,\n                            \"bb_y2\": y2,\n                            \"bb_x3\": x3,\n                            \"bb_y3\": y3,\n                            \"bb_x4\": x4,\n                            \"bb_y4\": y4,\n                            \"offset\": line['spans'][0]['offset'],\n                            \"length\": line['spans'][0]['length'],\n                        }\n                        \n                        ocr_data.append(line_info)\n\n                # extraction on word level\n                elif self.text_granularity == \"WORD\":\n                    for word in page['words']:\n                        x1, y1, x2, y2, x3, y3, x4, y4 = word['polygon']\n\n                        word_info = {\n                            \"page\": page['pageNumber'],\n                            \"text\": word['content'],\n                            \"confidence\": word['confidence'],\n                            \"bb_x1\": x1,\n                            \"bb_y1\": y1,\n                            \"bb_x2\": x2,\n                            \"bb_y2\": y2,\n                            \"bb_x3\": x3,\n                            \"bb_y3\": y3,\n                            \"bb_x4\": x4,\n                            \"bb_y4\": y4,\n                            \"offset\": word['span']['offset'],\n                            \"length\": word['span']['length'],\n                            }\n                        \n                        ocr_data.append(word_info)\n                \n                df = pd.DataFrame(ocr_data)\n\n                # aggregation on page level\n                if level.upper() == \"PAGE\":\n                    ocr_data = []\n                    page_info = {\n                            \"page\": page['pageNumber'],\n                            \"text\": \"\\n \".join(df['text']),\n                            \"avg_confidence\": average_confidence\n                            }\n                    ocr_data.append(page_info)\n                    \n                    df = pd.DataFrame(ocr_data)\n\n                parsed_result = pd.concat([parsed_result, df], ignore_index=True)\n\n        if self.model_id == 'prebuilt-read' and self.text_granularity.upper() == 'PARAGRAPH': # 'read' model doesn't provide semantic role, only 'layout' does\n            parsed_result = parsed_result.drop(columns=['role'])\n\n        return parsed_result\n\n    @retry_on_endpoint_connection_error(max_retries=n_con_retry, delay=retry_delay)\n    def analyze_document(self, document) -> AnalyzeResult:\n        \"\"\" Analyze the document and return the result\n\n        Parameters:\n        -----------\n        document:\n            io.BytesIO|str: document or url to document to analyze\n        \n        Returns:\n        --------\n        parsed_result:\n            pd.DataFrame: OCR results\n         \"\"\"\n        if not self.local_ocr:\n            if self.input_type.upper() == 'FILE':\n                poller = self.ocr_client.begin_analyze_document(model_id = self.model_id, \n                                                                analyze_request = document,\n                                                                content_type=\"application/octet-stream\",\n                                                                locale = self.locale\n                                                                )\n            elif self.input_type.upper() == 'URL':\n                poller = self.ocr_client.begin_analyze_document(model_id = self.model_id, \n                                                                analyze_request = AnalyzeDocumentRequest(url_source=document),\n                                                                locale = self.locale\n                                                                )\n            \n            result = poller.result()\n        else:\n            url = f\"{self.endpoint}/formrecognizer/documentModels/prebuilt-document:syncAnalyze?api-version=2022-08-31\"\n            headers = {\n                'accept': '*/*',\n                'Content-Type': 'application/octet-stream',\n            }\n            response = requests.post(url, headers=headers, data=document)\n            response_json = json.loads(response.text)\n            result = response_json['analyzeResult']\n\n        return result\n\nclass ExtractForm(OCRStrategy):\n    def __init__(self, ocr_client, kwargs):\n        self.ocr_client = ocr_client\n        self.local_ocr = kwargs.get('local_ocr', False)\n        self.input_type = kwargs.get('input_type', 'file')\n        self.file_location = kwargs.get('file_location', 'local')\n        self.locale = kwargs.get('locale', '')\n\n        if self.local_ocr:\n            self.endpoint = kwargs.get('endpoint', 'http://localhost:5000')\n\n    def parse_ocr_result(self, result) -> pd.DataFrame:\n        key_value_pairs = result['keyValuePairs']\n        form_data = []\n\n        for pair in key_value_pairs:\n            page_number = pair['key']['boundingRegions'][0]['pageNumber']\n            key = pair['key']['content']\n            key_x1, key_y1, key_x2, key_y2, key_x3, key_y3, key_x4, key_y4 = pair['key']['boundingRegions'][0]['polygon']\n            key_offset = pair['key']['spans'][0]['offset']\n            key_length = pair['key']['spans'][0]['length']\n\n            try:\n                value = pair['value']['content']\n                value_x1, value_y1, value_x2, value_y2, value_x3, value_y3, value_x4, value_y4 = pair['value']['boundingRegions'][0]['polygon']\n                value_offset = pair['value']['spans'][0]['offset']\n                value_length = pair['value']['spans'][0]['length']\n            except KeyError as e:\n                value_x1 = value_y1 = value_x2 = value_y2 = value_x3 = value_y3 = value_x4 = value_y4 = None\n                value_offset = value_length = None\n                value = None\n\n            key_value = {\n                'page_number': page_number,\n                'key': key,\n                'value': value,\n                'key_x1': key_x1,\n                'key_y1': key_y1,\n                'key_x2': key_x2,\n                'key_y2': key_y2,\n                'key_x3': key_x3,\n                'key_y3': key_y3,\n                'key_x4': key_x4,\n                'key_y4': key_y4,\n                'key_offset': key_offset,\n                'key_length': key_length,\n                'value_x1': value_x1,\n                'value_y1': value_y1,\n                'value_x2': value_x2,\n                'value_y2': value_y2,\n                'value_x3': value_x3,\n                'value_y3': value_y3,\n                'value_x4': value_x4,\n                'value_y4': value_y4,\n                'value_offset': value_offset,\n                'value_length': value_length,\n            }\n\n            form_data.append(key_value)\n        \n        df = pd.DataFrame(form_data)\n\n        return df\n        \n    @retry_on_endpoint_connection_error(max_retries=n_con_retry, delay=retry_delay)\n    def analyze_document(self, document) -> AnalyzeResult:\n        \n        if not local_ocr:\n            if self.input_type.upper() == 'FILE':\n                poller = self.ocr_client.begin_analyze_document( model_id = \"prebuilt-layout\", \n                                                            analyze_request = document,\n                                                            content_type=\"application/octet-stream\",\n                                                            locale = self.locale,\n                                                            features=['keyValuePairs']\n                                                            )\n            \n            elif self.input_type.upper() == 'URL':\n                poller = self.ocr_client.begin_analyze_document(model_id = \"prebuilt-layout\", \n                                                                analyze_request = AnalyzeDocumentRequest(url_source=document),\n                                                                locale = self.locale,\n                                                                features=['keyValuePairs']\n                                                                )\n            \n            result = poller.result()\n        else:\n            url = f\"{self.endpoint}/formrecognizer/documentModels/prebuilt-document:syncAnalyze?api-version=2022-08-31\"\n            headers = {\n                'accept': '*/*',\n                'Content-Type': 'application/octet-stream',\n            }\n            response = requests.post(url, headers=headers, data=document)\n            response_json = json.loads(response.text)\n            result = response_json['analyzeResult']\n        \n        return result\n\nclass ExtractQuery(OCRStrategy):\n    def __init__(self, ocr_client, kwargs):\n        self.ocr_client = ocr_client\n        self.input_type = kwargs.get('input_type', 'file')\n        self.file_location = kwargs.get('file_location', 'local')\n        self.locale = kwargs.get('locale', '')\n        self.query_fields = kwargs.get('query_fields', '')\n        self.query_exclude_metadata = kwargs.get('query_exclude_metadata', False)\n\n    def parse_ocr_result(self, result) -> pd.DataFrame:\n        query_data = []\n\n        for doc in result['documents']:\n            for query in self.query_fields:\n                if not self.query_exclude_metadata:\n                    x1, y1, x2, y2, x3, y3, x4, y4 = doc['fields'][query]['boundingRegions'][0]['polygon']\n                    query_info = {\n                        'page_number': doc['fields'][query]['boundingRegions'][0]['pageNumber'],\n                        'key': query,\n                        'value': doc['fields'][query]['content'],\n                        'confidence': doc['fields'][query]['confidence'],\n                        'type': doc['fields'][query]['type'],\n                        'x1': x1,\n                        'y1': y1,\n                        'x2': x2,\n                        'y2': y2,\n                        'x3': x3,\n                        'y3': y3,\n                        'x4': x4,\n                        'y4': y4,\n                        'offset': doc['fields'][query]['spans'][0]['offset'],\n                        'length': doc['fields'][query]['spans'][0]['length'],\n                    }\n                    query_data.append(query_info)\n                else:\n                    query_info = {\n                        'key': query,\n                        'value': doc['fields'][query]['content'],\n                    }\n                    query_data.append(query_info)\n\n        parsed_result = pd.DataFrame(query_data)\n\n        # if query_exclude_metadata, transpose results\n        if query_exclude_metadata:\n            parsed_result = parsed_result.set_index('key').T\n\n        return parsed_result\n        \n    @retry_on_endpoint_connection_error(max_retries=n_con_retry, delay=retry_delay)\n    def analyze_document(self, document) -> AnalyzeResult:\n        if self.input_type.upper() == 'FILE':\n            poller = self.ocr_client.begin_analyze_document(model_id = \"prebuilt-layout\", \n                                                        analyze_request = document,\n                                                        content_type = \"application/octet-stream\",\n                                                        locale = self.locale,\n                                                        features = [DocumentAnalysisFeature.QUERY_FIELDS],\n                                                        query_fields = self.query_fields,\n                                                        )\n        \n        elif self.input_type.upper() == 'URL':\n            poller = self.ocr_client.begin_analyze_document(model_id = \"prebuilt-layout\", \n                                                            analyze_request = AnalyzeDocumentRequest(url_source=document),\n                                                            locale = self.locale,\n                                                            features = [DocumentAnalysisFeature.QUERY_FIELDS],\n                                                            query_fields = self.query_fields,\n                                                            )\n        result = poller.result()\n\n        return result\n\nclass ExtractTable(OCRStrategy):\n    def __init__(self, ocr_client, kwargs): \n        self.ocr_client = ocr_client\n        self.local_ocr = kwargs.get('local_ocr', False)\n        self.input_type = kwargs.get('input_type', 'file')\n        self.file_location = kwargs.get('file_location', 'local')\n        self.locale = kwargs.get('locale', '')\n        self.table_output_format = kwargs.get('table_output_format', 'map')\n        self.select_table = kwargs.get('select_table', False)\n        self.table_selection_method = kwargs.get('table_selection_method', 'index')\n        self.table_selection_idx = kwargs.get('table_selection_idx', 0)\n        self.table_output_caslib = kwargs.get('table_output_caslib', 'work')\n\n        if self.local_ocr:\n            self.endpoint = kwargs.get('endpoint', 'http://localhost:5000')\n\n    def result_to_dfs(self, result) -> list:\n        tables = []\n        for table in result['tables']:\n            table_df = pd.DataFrame(columns=range(table['columnCount']), index=range(table['rowCount']))\n\n            for cell in table['cells']:\n                table_df.iloc[cell['rowIndex'], cell['columnIndex']] = cell['content']\n\n            # use the first row as column names\n            table_df.columns = table_df.iloc[0]\n            table_df = table_df[1:]\n            \n            tables.append(table_df)\n        return tables\n\n    # TABLE PARSING METHODS\n    def map_parsing(self, result) -> pd.DataFrame:\n        tables = []\n\n        # extract all table data\n        for index, table in enumerate(result['tables']):\n            if self.table_output_format.upper() == 'MAP':\n\n                if not isinstance(table, dict):\n                    table = table.as_dict()\n\n                df = pd.DataFrame.from_dict(table['cells'])\n\n                # extract page_number and polygon coordinates\n                df['page'] = df['boundingRegions'].apply(lambda x: x[0]['pageNumber'])\n                df['table_index'] = index\n                df['polygon'] = df['boundingRegions'].apply(lambda x: x[0]['polygon'])\n\n                # extract polygon coordinates\n                df['x1'] = df['polygon'].apply(lambda x: x[0])\n                df['y1'] = df['polygon'].apply(lambda x: x[1])\n                df['x2'] = df['polygon'].apply(lambda x: x[2])\n                df['y2'] = df['polygon'].apply(lambda x: x[3])\n                df['x3'] = df['polygon'].apply(lambda x: x[4])\n                df['y3'] = df['polygon'].apply(lambda x: x[5])\n                df['x4'] = df['polygon'].apply(lambda x: x[6])\n                df['y4'] = df['polygon'].apply(lambda x: x[7])\n\n                # extract offset and length\n                df['offset'] = df['spans'].apply(lambda x: int(x[0]['offset']) if x else None)\n                df['length'] = df['spans'].apply(lambda x: int(x[0]['length']) if x else None)\n\n                # drop unnecessary columns\n                df.drop(columns=['boundingRegions','spans', 'polygon'], inplace=True)\n\n                table_info = {\n                    'table_index': index,\n                    'row_count': table['rowCount'],\n                    'column_count': table['columnCount'],\n                    'cell_count': table['rowCount']*table['columnCount'],\n                    'table': df\n                }\n\n                tables.append(table_info)\n\n        # select specific table (optional)\n        if self.select_table:\n            if self.table_selection_method.upper() == 'INDEX':\n                parsed_result = tables[table_selection_idx]['table']\n            elif self.table_selection_method.upper() == 'SIZE':\n                # Find the entry with the highest cell_count using max function\n                table_most_cells = max(tables, key=lambda x: x['cell_count'], default=None)\n                parsed_result = table_most_cells['table'] if table_most_cells else None\n\n        else:\n            # combine all extracted tables (only works for output type 'map')\n            parsed_result = pd.concat([table['table'] for table in tables], ignore_index=True)\n\n        return parsed_result\n\n    def reference_parsing(self, result) -> pd.DataFrame: # TODO\n        tables = self.result_to_dfs(result)\n        table_info = []\n\n        for table in tables:\n            reference = uuid.uuid4()\n            reference = re.sub(r'^\\w{3}', 'tbl_', str(reference))\n            reference = reference.replace('-', '')\n\n            # save table to caslib\n            try: \n                SAS.logMessage(f'Save table {reference} to {self.table_output_caslib}', 'info')\n            except Exception as e:\n                SAS.logMessage(f'Failed to save table {reference} to caslib {self.table_output_caslib}', 'warning')\n                raise e\n            \n            table_info.append({\n                'out_library': self.table_output_caslib,\n                'table_reference': reference,\n                'row_count': table.shape[0],\n                'column_count': table.shape[1],\n            })\n\n        return pd.DataFrame(table_info)\n\n    def table_parsing(self, result) -> pd.DataFrame: #TODO\n        tables = self.result_to_dfs(result)\n        self.select_table = True\n\n        # select specific table \n        if self.select_table:\n            if self.table_selection_method.upper() == 'INDEX': # Table with index == table_selection_idx\n                parsed_result = tables[table_selection_idx]\n            elif self.table_selection_method.upper() == 'SIZE': # Table with most cells\n                table_most_cells = max(tables, key=lambda x: x.size, default=None)\n                try:\n                    parsed_result = table_most_cells\n                except:\n                    parsed_result = None\n\n            else:\n                raise ValueError(f'Invalid table selection method: {self.table_selection_method}')\n\n        return parsed_result\n\n    # TABLE PARSING METHODS MAPPING\n    parsing_methods = {\n        'MAP': map_parsing,\n        'REFERENCE': reference_parsing,\n        'TABLE': table_parsing\n    }\n\n    def parse_ocr_result(self, result) -> pd.DataFrame:\n        # call one of the parsing methods depending on the output format\n        parsing_method = table_output_format.upper()\n        parsed_result = self.parsing_methods.get(parsing_method)(self,result = result)\n\n        return parsed_result\n\n    @retry_on_endpoint_connection_error(max_retries=n_con_retry, delay=retry_delay)\n    def analyze_document(self, document) -> AnalyzeResult:\n        if not self.local_ocr:   \n            if self.input_type.upper() == 'FILE':\n                poller = self.ocr_client.begin_analyze_document(model_id = \"prebuilt-layout\", \n                                                            analyze_request = document,\n                                                            content_type = \"application/octet-stream\",\n                                                            locale = self.locale,\n                                                            )\n            \n            elif self.input_type.upper() == 'URL':\n                poller = self.ocr_client.begin_analyze_document(model_id = \"prebuilt-layout\", \n                                                                analyze_request = AnalyzeDocumentRequest(url_source=document),\n                                                                locale = self.locale\n                                                                )\n\n            result = poller.result()      \n        else:\n            url = f\"{self.endpoint}/formrecognizer/documentModels/prebuilt-document:syncAnalyze?api-version=2022-08-31\"\n            headers = {\n                'accept': '*/*',\n                'Content-Type': 'application/octet-stream',\n            }\n            response = requests.post(url, headers=headers, data=document)\n            response_json = json.loads(response.text)\n            result = response_json['analyzeResult']\n        \n        return result\n\n# class that processes the OCR\nclass OCRProcessor:\n    \"\"\" Class that processes the OCR depending on the strategy\"\"\"\n    def __init__(self, ocr_client: DocumentIntelligenceClient, ocr_type:str, **kwargs):\n        self.ocr_client = ocr_client\n        self.ocr_type = ocr_type\n        self.kwargs = kwargs\n\n        # Define the strategy mapping\n        self.strategy_mapping = {\n            ('text'): ExtractText,\n            ('form'): ExtractForm,\n            ('query'): ExtractQuery,\n            ('table'): ExtractTable\n        }\n\n        # Get the strategy class, parameters and initiate strategy\n        strategy_class = self.strategy_mapping[(self.ocr_type)]\n        self.strategy = strategy_class(ocr_client = self.ocr_client, kwargs = self.kwargs)\n\n    def analyze_document(self, document:io.BytesIO|str) -> AnalyzeResult:\n        \"\"\" Analyze the document and return the result\n        \n        Parameters:\n        -----------\n        document:\n            io.BytesIO|str: document to analyze\n            \n        Returns:\n        --------\n        result:\n            AnalyzeResult: OCR results\"\"\"\n        return self.strategy.analyze_document(document)\n    \n    def parse_ocr_result(self, result:AnalyzeResult) -> pd.DataFrame:\n        \"\"\" Parse the OCR result and return the result\n\n        Parameters:\n        -----------\n        result:\n            AnalyzeResult: OCR results\n\n        Returns:\n        --------\n        parsed_result:\n            pd.DataFrame: parsed OCR results\n        \"\"\"\n        return self.strategy.parse_ocr_result(result)\n    \n###################### PREPARATION ######################\nif input_mode.upper() == 'BATCH':                       # When input_mode = 'batch' try to load the file list using the input_table_name\n    try:\n        file_list = SAS.sd2df(input_table_name)\n        pass\n    except Exception as e:\n        SAS.logMessage('No input table was provided!', 'error')\n        pass\nelse:\n\tfile_list = ''\nif ocr_type.upper() == 'QUERY':                         # prepare the query string to the right format\n    try:\n        query_fields = prepare_query(query_fields)\n    except ValueError as e:\n        SAS.logMessage(f'REGEX ERROR: {e}', 'error')\n        exit()\n    except Exception as e:\n        SAS.logMessage(f'ERROR: {e}', 'error')\n        exit()  \nif input_mode.upper() == 'SINGLE':                      # if input_mode = 'single', create a dataframe with the file path\n    if input_type.upper() == 'URL':                     \n        file_path = file_url\n    file_list = pd.DataFrame({'file_path': [file_path]})\n    path_column = 'file_path'\nif save_json:                                           # check if output folder should be created (if save_json = True)\n    # check if output folder exists\n    if not os.path.exists(json_output_folder):\n        try:\n            os.makedirs(json_output_folder)\n            SAS.logMessage(f'Created output folder at: {json_output_folder}!', 'info')\n        except OSError as e:\n            SAS.logMessage(f'OSError - Could not create output folder {json_output_folder}!', 'info')\n            exit()\n    \n    # check if output folder is writable\n    if not os.access(json_output_folder, os.W_OK):\n        raise OSError(f'OSError - Output folder {json_output_folder} is not writable!')\n        exit()\nif local_ocr:                                           # check if local ocr container is running and reachable\n    for check in ['status', 'ready', 'containerliveness']:\n        url = f'{local_ocr_endpoint}/{check}'\n        headers = {\n            'accept': '*/*',\n        }\n        response = requests.get(url, headers=headers)\n        if response.status_code != 200:\n            raise ValueError(f'Local OCR Container is not running or cant be reached! {check}: {response.status_code}')\n            exit()\n    SAS.logMessage(f'Local OCR Container is running at: {local_ocr_endpoint}', 'info')\n                                                                           \n###################### PRE-CHECKS ######################\nif input_mode.upper() == 'SINGLE':                                      # When input type is 'file' check if the file is located on the server not SAS Content\n\ttry:\n\t\tocr_document_path = file_path.split(':', 1)[1]\n\texcept Exception as e:\n\t\t#SAS.logMessage(\"Please select a valid path. Files have to be located on SAS Server (not SAS Content)!\", 'error')\n\t\texit()\nif ocr_type.upper() == 'TABLE' and table_output_format.upper() == 'TABLE' and file_list.shape[0] > 1:   # if table_output_format = 'table', check if only one row in the file_list\n    raise ValueError('Only one file is supported if table_output_format = \"table\"!')\n    exit()\nif input_mode.upper() == 'BATCH' and file_list.shape[0] < 1:            # if input_mode = 'batch' and input_type = 'file', check if the file list is not empty\n    raise ValueError('Provided file list is empty!')\n    exit()\nif local_ocr:\n    if ocr_type.upper() == 'QUERY':\n        SAS.logMessage('Local OCR Container does not support query extraction!', 'error')\n        exit()\n\n###################### EXECUTION ######################\n# define all possible parameters for the OCR\nocr_params = {\n              # general\n              'locale': locale,\n              'input_type': input_type,\n              'local_ocr': local_ocr,\n              # for text extraction\n              'text_granularity': text_granularity,\n              'model_id': model_id,\n              # for query extraction\n              'query_fields': query_fields,\n              'query_exclude_metadata': query_exclude_metadata,\n              # for table extraction\n              'table_output_format': table_output_format,\n              'selected_table': select_table,\n              'selection_method': table_selection_method,\n              'table_selection_idx': table_selection_idx,\n              'table_output_caslib': table_output_library,\n              }\n\n# initiate dataframe to store results and status\nocr_results = pd.DataFrame()\nstatus = pd.DataFrame()\n\n# initiate the OCR client and processor\nif not local_ocr:\n    ocr_client = DocumentIntelligenceClient(endpoint = azure_endpoint, \n                                        credential = AzureKeyCredential(azure_key),\n                                        api_version = API_VERSION\n                                        )\nelse:\n    ocr_client = {'endpoint': local_ocr_endpoint}\n\nocr_processor = OCRProcessor(ocr_client = ocr_client, \n                             ocr_type = ocr_type, \n                             **ocr_params\n                             )\n\ndef process_files(file_list, ocr_processor, path_column):\n    \"\"\" Process the files in the file_list using the ocr_processor\n\n    Parameters:\n    -----------\n    file_list:\n        pd.DataFrame: dataframe containing the file paths\n    ocr_processor:\n        OCRProcessor: OCR processor\n    path_column:\n        str: column that contains the file path\n    \"\"\"\n    # go through every document in the list\n    global ocr_results, status\n\n    for _, row in file_list.iterrows():\nLocal OCR Container is running!\n        SAS.logMessage(f'Processing file: {row[path_column]}', 'info')\n        done = False\n        n_rows = 0\n        error_type = ''\n        message = ''\n        start = datetime.now()\n\n        # perform the OCR\n        if input_type.upper() == 'FILE':\n            with open(row[path_column], 'rb') as document:\n                document = io.BytesIO(document.read())\n        elif input_type.upper() == 'URL':\n            document = row[path_column]\n        else:\n            raise ValueError(f'Invalid input type: {input_type}!')\n        \n        try:\n            # run ocr processing on the document\n            result = ocr_processor.analyze_document(document = document)\n\n            # parse the ocr result\n            parsed_result = ocr_processor.parse_ocr_result(result = result)\n\n            # add the file path to the result\n            if not parsed_result.empty:\n                parsed_result[path_column] = row[path_column]\n\n            # append result to the overall result table\n            if not parsed_result.empty:\n                ocr_results = pd.concat([ocr_results, parsed_result], ignore_index=True)\n                n_rows = parsed_result.shape[0]\n\n            done = True\n\n        except Exception as e:\n            error_type = type(e).__name__\n            message = str(e)\n            SAS.logMessage(f'{error_type} - {message} - for {row[path_column]}', 'warning')\n        \n        # Post processing\n        if ocr_type.upper() == 'TABLE' and table_output_format.upper() == 'TABLE': # if output_table_format = 'table', drop the path_column\n            ocr_results.drop(columns=[path_column], inplace=True)\n\n        if save_json: # if save_json = True, save the azure ocr result as json\n            try: \n                with open(f'{json_output_folder}/{row[path_column].split(\"/\")[-1].split(\".\")[0]}_{ocr_type}.json', 'w') as f:\n                    json.dump(result.as_dict(), f)\n            except Exception as e:\n                error_type = type(e).__name__\n                message = str(e)\n                SAS.logMessage(f'Warning: {error_type} - {message} for {row[path_column]}', 'warning')\n\n        # update the status\n        doc_status = {'file': row[path_column],\n                    'done': done,\n                    'num_rows': n_rows,\n                    'error_type': error_type,\n                    'message': message,\n                    'start': start,\n                    'end': datetime.now(),\n                    'duration_seconds': round((datetime.now() - start).total_seconds(), 3)\n                    }\n        status = pd.concat([status, pd.DataFrame(doc_status, index=[0])], ignore_index=True)\n\n# Parallel processing of the files\ndf_split = np.array_split(file_list, n_threads)\nthreads = []\n\nif file_list.shape[0] < n_threads:\n    n_threads = file_list.shape[0]\n\nfor i in range(n_threads):\n    paths = df_split[i]\n    thread = threading.Thread(target=process_files, args=(paths, ocr_processor, path_column))\n    threads.append(thread)\n    thread.start()\n    SAS.logMessage(f'Started thread {i+1} of {n_threads}!', 'info')\n\n# Wait for all threads to complete\nfor index, thread in enumerate(threads):\n    thread.join()\n    SAS.logMessage(f'Thread {index+1} of {n_threads} completed!', 'info')\n\nSAS.logMessage(f'FINISHED - Successfully processed {status[\"done\"].sum()} / {status.shape[0]} files!', 'info')\n\n# Output the results\nSAS.df2sd(ocr_results, SAS.symget(\"_outputtable1\"))\nif output_status_table:\n    SAS.df2sd(status, SAS.symget(\"_outputtable2\"))\n    pass\n\nendsubmit;\nrun;\n\nproc python terminate; quit; "},"properties":{},"ui":"{\n\t\"showPageContentOnly\": true,\n\t\"pages\": [\n\t\t{\n\t\t\t\"id\": \"pageSettings\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Settings\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"extractions_settings\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"OCR Settings\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_type\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"OCR-Type:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"text\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Text\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"form\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Forms\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"query\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Queries\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"table\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Tables\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"text_settings\",\n\t\t\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\t\t\"label\": \"Text\",\n\t\t\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$ocr_type\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"text\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"text_granularity\",\n\t\t\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Extraction Level:\",\n\t\t\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\"value\": \"document\",\n\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Document\"\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\"value\": \"page\",\n\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Page\"\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\"value\": \"paragraph\",\n\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Paragraph\"\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\"value\": \"line\",\n\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Line\"\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\"value\": \"word\",\n\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Word\"\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\"$ocr_type\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"text\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"extract_pragraph_roles\",\n\t\t\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Extract Paragraph Roles\",\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\"$text_granularity\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"paragraph\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"extract_paragraph_role_info\",\n\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\t\t\"text\": \"Enabling this option might have cost implication. Links with more information about Azure Document Intelligent pricing can be found in the About page of this custom step. \",\n\t\t\t\t\t\t\t\t\t\"visible\": \"$extract_pragraph_roles\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"query_settings\",\n\t\t\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\t\t\"label\": \"Query\",\n\t\t\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$ocr_type\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"query\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"ocr_query_fields\",\n\t\t\t\t\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Query Fields:\",\n\t\t\t\t\t\t\t\t\t\"placeholder\": \"seperate, your, fields_with, commas\",\n\t\t\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\"$ocr_type\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"query\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"query_keys_info\",\n\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\t\t\"text\": \"Make sure your keys are regex compliant by substituting blanks with underscores ('_'). Do not add quotes.\",\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\"$ocr_type\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"query\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"query_exclude_metadata\",\n\t\t\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Only Output Query Results\",\n\t\t\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"query_exclude_metadata_info\",\n\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\t\t\"text\": \"When unselected, the ouput will be a key-value table including OCR metadata like field location, etc...\",\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\"$ocr_type\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"query\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"table_settings\",\n\t\t\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\t\t\"label\": \"Table\",\n\t\t\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$ocr_type\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"table\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"table_output_format\",\n\t\t\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Extraction Mode:\",\n\t\t\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\"value\": \"map\",\n\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Mapping-Table\"\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\"value\": \"reference\",\n\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Reference-Table\"\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\"value\": \"table\",\n\t\t\t\t\t\t\t\t\t\t\t\"label\": \"One Table\"\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"table_settings_map_info\",\n\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\t\t\"text\": \"Outputs one table containing all cells of every processed document in the following format [row_id, column_id, cell_content]\",\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\"$table_output_format\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"map\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"table_settings_table_info\",\n\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\t\t\"text\": \"Outputs table in its original form. NOTE: ONLY SUPPORTS THE OUTPUT OF A SINGLE TABLE! \\nFor more information please refer to the About section of the custom step.\",\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\"$table_output_format\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"table\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"table_settings_reference_info\",\n\t\t\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\t\t\"text\": \"Saves all extracted tables in the defined librarary and outputs a reference table. \",\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\"$table_output_format\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"reference\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"table_output_library\",\n\t\t\t\t\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Output Library:\",\n\t\t\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\"$table_output_format\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"reference\"\n\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\"enabled\": [\n\t\t\t\t\t\t\t\t\t\t\"$table_output_format\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"reference\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"select_table\",\n\t\t\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Enable Table Selection\",\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\"$table_output_format\",\n\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\"reference\"\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"id\": \"table_filter_settings\",\n\t\t\t\t\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Filter Settings\",\n\t\t\t\t\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\t\"$select_table\",\n\t\t\t\t\t\t\t\t\t\t\t\"|\",\n\t\t\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\t\t\"$table_output_format\",\n\t\t\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\t\t\"table\"\n\t\t\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\t\t\"$table_output_format\",\n\t\t\t\t\t\t\t\t\t\t\t\"!=\",\n\t\t\t\t\t\t\t\t\t\t\t\"map\"\n\t\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\"id\": \"tabel_selection_method\",\n\t\t\t\t\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Selection Method:\",\n\t\t\t\t\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\"value\": \"index\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Index\"\n\t\t\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\t\t\"value\": \"size\",\n\t\t\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Table Size\"\n\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\t\t\"id\": \"table_selection_idx\",\n\t\t\t\t\t\t\t\t\t\t\t\"type\": \"numberfield\",\n\t\t\t\t\t\t\t\t\t\t\t\"label\": \"Table-Index:\",\n\t\t\t\t\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\t\t\t\t\"min\": 0,\n\t\t\t\t\t\t\t\t\t\t\t\"excludemin\": false,\n\t\t\t\t\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\t\t\t\t\"$tabel_selection_method\",\n\t\t\t\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\t\t\t\"index\"\n\t\t\t\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\t\t\t\"integer\": true\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"input_settings\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Input Settings\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"input_mode\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Input Mode:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"batch\",\n\t\t\t\t\t\t\t\t\t\"label\": \"A list of files (table)\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"single\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Single file (path)\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"input_type\",\n\t\t\t\t\t\t\t\"type\": \"radiogroup\",\n\t\t\t\t\t\t\t\"label\": \"Input Type:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"file\",\n\t\t\t\t\t\t\t\t\t\"label\": \"Local File(s)\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"value\": \"url\",\n\t\t\t\t\t\t\t\t\t\"label\": \"URL(s)\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"input_table_name\",\n\t\t\t\t\t\t\t\"type\": \"inputtable\",\n\t\t\t\t\t\t\t\"label\": \"Input Table:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"Table containing file paths\",\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$input_mode\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"batch\"\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"path_column\",\n\t\t\t\t\t\t\t\"type\": \"columnselector\",\n\t\t\t\t\t\t\t\"label\": \"File path/URL Column:\",\n\t\t\t\t\t\t\t\"order\": false,\n\t\t\t\t\t\t\t\"columntype\": \"c\",\n\t\t\t\t\t\t\t\"max\": 1,\n\t\t\t\t\t\t\t\"min\": null,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t\"$input_mode\",\n\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\"batch\"\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"readonly\": false,\n\t\t\t\t\t\t\t\"table\": \"input_table_name\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"file_path\",\n\t\t\t\t\t\t\t\"type\": \"path\",\n\t\t\t\t\t\t\t\"label\": \"File Path:\",\n\t\t\t\t\t\t\t\"pathtype\": \"file\",\n\t\t\t\t\t\t\t\"placeholder\": \"sasserver:/path/to/file/on/saserver\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\"$input_mode\",\n\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\"single\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\"$input_type\",\n\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\"file\"\n\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"file_url\",\n\t\t\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\t\t\"label\": \"File URL: \",\n\t\t\t\t\t\t\t\"placeholder\": \"https://www.example.com/image.jpg\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"visible\": [\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\"$input_mode\",\n\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\"single\"\n\t\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\t\"&\",\n\t\t\t\t\t\t\t\t[\n\t\t\t\t\t\t\t\t\t\"$input_type\",\n\t\t\t\t\t\t\t\t\t\"=\",\n\t\t\t\t\t\t\t\t\t\"url\"\n\t\t\t\t\t\t\t\t]\n\t\t\t\t\t\t\t]\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"textInputSettings\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Hint: You can find language related settings on the Advanced Settings page.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"output_settings\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Output Settings\",\n\t\t\t\t\t\"open\": true,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"outputtable1\",\n\t\t\t\t\t\t\t\"type\": \"outputtable\",\n\t\t\t\t\t\t\t\"label\": \"OCR Output Table:\",\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"placeholder\": \"Table to output OCR results\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"output_status_table\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Output Processing Status Table\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"outputtable2\",\n\t\t\t\t\t\t\t\"type\": \"outputtable\",\n\t\t\t\t\t\t\t\"label\": \"Status Output Table:\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"$output_status_table\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"pageConnection\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Azure Connection\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"azure_endpoint\",\n\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\"label\": \"Azure Resource Endpoint:\",\n\t\t\t\t\t\"placeholder\": \"https://your-resource.cognitiveservices.azure.com/\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"visible\": \"!$local_ocr\",\n\t\t\t\t\t\"enabled\": \"!$local_ocr\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"azure_key\",\n\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\"label\": \"Azure Secret Key:\",\n\t\t\t\t\t\"placeholder\": \"SECRET_KEY\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"visible\": \"!$local_ocr\",\n\t\t\t\t\t\"enabled\": \"!$local_ocr\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"local_ocr_endpoint\",\n\t\t\t\t\t\"type\": \"textfield\",\n\t\t\t\t\t\"label\": \"Local Container Endpoint\",\n\t\t\t\t\t\"placeholder\": \"https://localhost:5000\",\n\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\"visible\": \"$local_ocr\",\n\t\t\t\t\t\"enabled\": \"$local_ocr\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"local_ocr\",\n\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\"label\": \"Use local Document Intelligence Container\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"textAzureConnection\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"For more information about the creation of Azure AI Document Intelligence ressources and access, follow the documentation linked in the about page. \",\n\t\t\t\t\t\"visible\": \"!$local_ocr\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"textAzureLocalContainer\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"PLEASE NOTE:\\n- Enabling this option does not create a container. You can find information regarding deployment in the about page.\\n- Local document intelligence container do not support query extraction. \\n- Only the 'General Document' container is supported\\n- For more info read the documentation linked in the about page\",\n\t\t\t\t\t\"visible\": \"$local_ocr\"\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"pageAdvanced\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"Advanced Settings\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"advanced_language\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Language\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"locale_info_text\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"NOTE: Languages are detected automatically. Only select a language if you want to force Document Intelligence to use only this language for detection.  For more information follow the link in the About page. \",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"ocr_locale\",\n\t\t\t\t\t\t\t\"type\": \"dropdown\",\n\t\t\t\t\t\t\t\"label\": \"Force Language for OCR:\",\n\t\t\t\t\t\t\t\"items\": [\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Abaza\",\n\t\t\t\t\t\t\t\t\t\"value\": \"abq\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Abkhazian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ab\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Achinese\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ace\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Acoli\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ach\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Adangme\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ada\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Adyghe\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ady\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Afar\",\n\t\t\t\t\t\t\t\t\t\"value\": \"aa\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Afrikaans\",\n\t\t\t\t\t\t\t\t\t\"value\": \"af\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Akan\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ak\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Albanian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sq\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Algonquin\",\n\t\t\t\t\t\t\t\t\t\"value\": \"alq\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Angika (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"anp\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Arabic\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ar\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Asturian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ast\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Asu (Tanzania)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"asa\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Avaric\",\n\t\t\t\t\t\t\t\t\t\"value\": \"av\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Awadhi-Hindi (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"awa\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Aymara\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ay\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Azerbaijani (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"az\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bafia\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ksf\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bagheli\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bfy\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bambara\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bm\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bashkir\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ba\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Basque\",\n\t\t\t\t\t\t\t\t\t\"value\": \"eu\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Belarusian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"be\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bemba (Zambia)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bem\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bena (Tanzania)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bez\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bhojpuri-Hindi (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bho\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bikol\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bik\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bini\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bin\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bislama\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bodo (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"brx\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bosnian (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bs\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Brajbha\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bra\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Breton\",\n\t\t\t\t\t\t\t\t\t\"value\": \"br\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bulgarian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bg\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Bundeli\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bns\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Buryat (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bua\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Catalan\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ca\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Cebuano\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ceb\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Chamling\",\n\t\t\t\t\t\t\t\t\t\"value\": \"rab\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Chamorro\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ch\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Chechen\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ce\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Chhattisgarhi (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"hne\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Chiga\",\n\t\t\t\t\t\t\t\t\t\"value\": \"cgg\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Chinese Simplified\",\n\t\t\t\t\t\t\t\t\t\"value\": \"zh-Hans\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Chinese Traditional\",\n\t\t\t\t\t\t\t\t\t\"value\": \"zh-Hant\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Choctaw\",\n\t\t\t\t\t\t\t\t\t\"value\": \"cho\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Chukot\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ckt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Chuvash\",\n\t\t\t\t\t\t\t\t\t\"value\": \"cv\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Cornish\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kw\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Corsican\",\n\t\t\t\t\t\t\t\t\t\"value\": \"co\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Cree\",\n\t\t\t\t\t\t\t\t\t\"value\": \"cr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Creek\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mus\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Crimean Tatar (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"crh\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Croatian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"hr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Crow\",\n\t\t\t\t\t\t\t\t\t\"value\": \"cro\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Czech\",\n\t\t\t\t\t\t\t\t\t\"value\": \"cs\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Danish\",\n\t\t\t\t\t\t\t\t\t\"value\": \"da\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Dargwa\",\n\t\t\t\t\t\t\t\t\t\"value\": \"dar\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Dari\",\n\t\t\t\t\t\t\t\t\t\"value\": \"prs\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Dhimal (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"dhi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Dogri (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"doi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Duala\",\n\t\t\t\t\t\t\t\t\t\"value\": \"dua\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Dungan\",\n\t\t\t\t\t\t\t\t\t\"value\": \"dng\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Dutch\",\n\t\t\t\t\t\t\t\t\t\"value\": \"nl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Efik\",\n\t\t\t\t\t\t\t\t\t\"value\": \"efi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"English\",\n\t\t\t\t\t\t\t\t\t\"value\": \"en\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Erzya (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"myv\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Estonian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"et\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Faroese\",\n\t\t\t\t\t\t\t\t\t\"value\": \"fo\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Fijian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"fj\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Filipino\",\n\t\t\t\t\t\t\t\t\t\"value\": \"fil\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Finnish\",\n\t\t\t\t\t\t\t\t\t\"value\": \"fi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Fon\",\n\t\t\t\t\t\t\t\t\t\"value\": \"fon\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"French\",\n\t\t\t\t\t\t\t\t\t\"value\": \"fr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Friulian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"fur\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Ga\",\n\t\t\t\t\t\t\t\t\t\"value\": \"gaa\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Gagauz (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"gag\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Galician\",\n\t\t\t\t\t\t\t\t\t\"value\": \"gl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Ganda\",\n\t\t\t\t\t\t\t\t\t\"value\": \"lg\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Gayo\",\n\t\t\t\t\t\t\t\t\t\"value\": \"gay\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"German\",\n\t\t\t\t\t\t\t\t\t\"value\": \"de\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Gilbertese\",\n\t\t\t\t\t\t\t\t\t\"value\": \"gil\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Gondi (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"gon\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Greek\",\n\t\t\t\t\t\t\t\t\t\"value\": \"el\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Greenlandic\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Guarani\",\n\t\t\t\t\t\t\t\t\t\"value\": \"gn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Gurung (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"gvr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Gusii\",\n\t\t\t\t\t\t\t\t\t\"value\": \"guz\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Haitian Creole\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ht\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Halbi (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"hlb\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Hani\",\n\t\t\t\t\t\t\t\t\t\"value\": \"hni\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Haryanvi\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bgc\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Hawaiian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"haw\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Hebrew\",\n\t\t\t\t\t\t\t\t\t\"value\": \"he\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Herero\",\n\t\t\t\t\t\t\t\t\t\"value\": \"hz\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Hiligaynon\",\n\t\t\t\t\t\t\t\t\t\"value\": \"hil\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Hindi\",\n\t\t\t\t\t\t\t\t\t\"value\": \"hi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Hmong Daw (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mww\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Ho (Devanagiri)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"hoc\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Hungarian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"hu\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Iban\",\n\t\t\t\t\t\t\t\t\t\"value\": \"iba\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Icelandic\",\n\t\t\t\t\t\t\t\t\t\"value\": \"is\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Igbo\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ig\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Iloko\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ilo\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Inari Sami\",\n\t\t\t\t\t\t\t\t\t\"value\": \"smn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Indonesian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"id\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Ingush\",\n\t\t\t\t\t\t\t\t\t\"value\": \"inh\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Interlingua\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ia\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Inuktitut (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"iu\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Irish\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ga\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Italian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"it\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Japanese\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ja\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Jaunsari (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"Jns\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Javanese\",\n\t\t\t\t\t\t\t\t\t\"value\": \"jv\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Jola-Fonyi\",\n\t\t\t\t\t\t\t\t\t\"value\": \"dyo\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"K'iche'\",\n\t\t\t\t\t\t\t\t\t\"value\": \"quc\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kabardian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kbd\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kabuverdianu\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kea\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kachin (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kac\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kalenjin\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kln\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kalmyk\",\n\t\t\t\t\t\t\t\t\t\"value\": \"xal\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kangri (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"xnr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kanuri\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kara-Kalpak (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kaa-cyrl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kara-Kalpak (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kaa\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Karachay-Balkar\",\n\t\t\t\t\t\t\t\t\t\"value\": \"krc\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kashubian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"csb\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kazakh (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kk-cyrl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kazakh (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kk-latn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Khakas\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kjh\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Khaling\",\n\t\t\t\t\t\t\t\t\t\"value\": \"klr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Khasi\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kha\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kikuyu\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ki\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kildin Sami\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sjd\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kinyarwanda\",\n\t\t\t\t\t\t\t\t\t\"value\": \"rw\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Komi\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kv\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kongo\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kg\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Korean\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ko\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Korku\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kfq\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Koryak\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kpy\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kosraean\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kos\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kpelle\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kpe\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kuanyama\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kj\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kumyk (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kum\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kurdish (Arabic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ku-arab\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kurdish (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ku-latn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kurukh (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kru\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Kyrgyz (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ky\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Lak\",\n\t\t\t\t\t\t\t\t\t\"value\": \"lbe\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Lakota\",\n\t\t\t\t\t\t\t\t\t\"value\": \"lkt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Latin\",\n\t\t\t\t\t\t\t\t\t\"value\": \"la\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Latvian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"lv\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Lezghian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"lex\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Lingala\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ln\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Lithuanian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"lt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Lower Sorbian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"dsb\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Lozi\",\n\t\t\t\t\t\t\t\t\t\"value\": \"loz\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Lule Sami\",\n\t\t\t\t\t\t\t\t\t\"value\": \"smj\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Luo (Kenya and Tanzania)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"luo\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Luxembourgish\",\n\t\t\t\t\t\t\t\t\t\"value\": \"lb\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Luyia\",\n\t\t\t\t\t\t\t\t\t\"value\": \"luy\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Macedonian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mk\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Machame\",\n\t\t\t\t\t\t\t\t\t\"value\": \"jmc\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Madurese\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mad\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Mahasu Pahari (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bfz\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Makhuwa-Meetto\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mgh\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Makonde\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kde\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Malagasy\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mg\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Malay (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ms\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Maltese\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Malto (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"kmj\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Mandinka\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mnk\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Manx\",\n\t\t\t\t\t\t\t\t\t\"value\": \"gv\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Maori\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Mapudungun\",\n\t\t\t\t\t\t\t\t\t\"value\": \"arn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Marathi\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Mari (Russia)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"chm\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Masai\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mas\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Mende (Sierra Leone)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"men\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Meru\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mer\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Meta'\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mgo\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Minangkabau\",\n\t\t\t\t\t\t\t\t\t\"value\": \"min\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Mohawk\",\n\t\t\t\t\t\t\t\t\t\"value\": \"moh\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Mongolian (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Mongondow\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mog\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Montenegrin (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"cnr-cyrl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Montenegrin (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"cnr-latn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Morisyen\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mfe\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Mundang\",\n\t\t\t\t\t\t\t\t\t\"value\": \"mua\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Nahuatl\",\n\t\t\t\t\t\t\t\t\t\"value\": \"nah\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Navajo\",\n\t\t\t\t\t\t\t\t\t\"value\": \"nv\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Ndonga\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ng\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Neapolitan\",\n\t\t\t\t\t\t\t\t\t\"value\": \"nap\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Nepali\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ne\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Ngomba\",\n\t\t\t\t\t\t\t\t\t\"value\": \"jgo\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Niuean\",\n\t\t\t\t\t\t\t\t\t\"value\": \"niu\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Nogay\",\n\t\t\t\t\t\t\t\t\t\"value\": \"nog\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"North Ndebele\",\n\t\t\t\t\t\t\t\t\t\"value\": \"nd\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Northern Sami (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sme\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Norwegian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"no\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Nyanja\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ny\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Nyankole\",\n\t\t\t\t\t\t\t\t\t\"value\": \"nyn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Nzima\",\n\t\t\t\t\t\t\t\t\t\"value\": \"nzi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Occitan\",\n\t\t\t\t\t\t\t\t\t\"value\": \"oc\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Ojibwa\",\n\t\t\t\t\t\t\t\t\t\"value\": \"oj\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Oromo\",\n\t\t\t\t\t\t\t\t\t\"value\": \"om\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Ossetic\",\n\t\t\t\t\t\t\t\t\t\"value\": \"os\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Pampanga\",\n\t\t\t\t\t\t\t\t\t\"value\": \"pam\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Pangasinan\",\n\t\t\t\t\t\t\t\t\t\"value\": \"pag\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Papiamento\",\n\t\t\t\t\t\t\t\t\t\"value\": \"pap\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Pashto\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ps\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Pedi\",\n\t\t\t\t\t\t\t\t\t\"value\": \"nso\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Persian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"fa\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Polish\",\n\t\t\t\t\t\t\t\t\t\"value\": \"pl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Portuguese\",\n\t\t\t\t\t\t\t\t\t\"value\": \"pt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Punjabi (Arabic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"pa\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Quechua\",\n\t\t\t\t\t\t\t\t\t\"value\": \"qu\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Ripuarian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ksh\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Romanian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ro\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Romansh\",\n\t\t\t\t\t\t\t\t\t\"value\": \"rm\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Rundi\",\n\t\t\t\t\t\t\t\t\t\"value\": \"rn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Russian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ru\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Rwa\",\n\t\t\t\t\t\t\t\t\t\"value\": \"rwk\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Sadri (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sck\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Sakha\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sah\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Samburu\",\n\t\t\t\t\t\t\t\t\t\"value\": \"saq\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Samoan (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sm\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Sango\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sg\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Sangu (Gabon)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"snq\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Sanskrit (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sa\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Santali(Devanagiri)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sat\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Scots\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sco\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Scottish Gaelic\",\n\t\t\t\t\t\t\t\t\t\"value\": \"gd\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Sena\",\n\t\t\t\t\t\t\t\t\t\"value\": \"seh\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Serbian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Serbian (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sr-cyrl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Shambala\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ksb\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Shona\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Siksika\",\n\t\t\t\t\t\t\t\t\t\"value\": \"bla\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Sirmauri (Devanagari)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"srx\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Skolt Sami\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sms\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Slovak\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sk\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Slovenian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Soga\",\n\t\t\t\t\t\t\t\t\t\"value\": \"xog\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Somali (Arabic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"so\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Somali (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"so-latn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Songhai\",\n\t\t\t\t\t\t\t\t\t\"value\": \"son\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"South Ndebele\",\n\t\t\t\t\t\t\t\t\t\"value\": \"nr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Southern Altai\",\n\t\t\t\t\t\t\t\t\t\"value\": \"alt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Southern Sami\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sma\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Southern Sotho\",\n\t\t\t\t\t\t\t\t\t\"value\": \"st\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Spanish\",\n\t\t\t\t\t\t\t\t\t\"value\": \"es\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Sundanese\",\n\t\t\t\t\t\t\t\t\t\"value\": \"su\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Swahili (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sw\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Swati\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ss\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Swedish\",\n\t\t\t\t\t\t\t\t\t\"value\": \"sv\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tabassaran\",\n\t\t\t\t\t\t\t\t\t\"value\": \"tab\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tachelhit\",\n\t\t\t\t\t\t\t\t\t\"value\": \"shi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tahitian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ty\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Taita\",\n\t\t\t\t\t\t\t\t\t\"value\": \"dav\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tajik (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"tg\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tamil\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ta\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tatar (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"tt-cyrl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tatar (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"tt\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Teso\",\n\t\t\t\t\t\t\t\t\t\"value\": \"teo\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tetum\",\n\t\t\t\t\t\t\t\t\t\"value\": \"tet\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Thai\",\n\t\t\t\t\t\t\t\t\t\"value\": \"th\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Thangmi\",\n\t\t\t\t\t\t\t\t\t\"value\": \"thf\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tok Pisin\",\n\t\t\t\t\t\t\t\t\t\"value\": \"tpi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tongan\",\n\t\t\t\t\t\t\t\t\t\"value\": \"to\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tsonga\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ts\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tswana\",\n\t\t\t\t\t\t\t\t\t\"value\": \"tn\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Turkish\",\n\t\t\t\t\t\t\t\t\t\"value\": \"tr\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Turkmen (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"tk\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Tuvan\",\n\t\t\t\t\t\t\t\t\t\"value\": \"tyv\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Udmurt\",\n\t\t\t\t\t\t\t\t\t\"value\": \"udm\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Uighur (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ug-cyrl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Ukrainian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"uk\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Upper Sorbian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"hsb\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Urdu\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ur\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Uyghur (Arabic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"ug\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Uzbek (Arabic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"uz-arab\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Uzbek (Cyrillic)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"uz-cyrl\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Uzbek (Latin)\",\n\t\t\t\t\t\t\t\t\t\"value\": \"uz\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Vietnamese\",\n\t\t\t\t\t\t\t\t\t\"value\": \"vi\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Volapük\",\n\t\t\t\t\t\t\t\t\t\"value\": \"vo\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Vunjo\",\n\t\t\t\t\t\t\t\t\t\"value\": \"vun\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Walser\",\n\t\t\t\t\t\t\t\t\t\"value\": \"wae\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Welsh\",\n\t\t\t\t\t\t\t\t\t\"value\": \"cy\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Western Frisian\",\n\t\t\t\t\t\t\t\t\t\"value\": \"fy\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Wolof\",\n\t\t\t\t\t\t\t\t\t\"value\": \"wo\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Xhosa\",\n\t\t\t\t\t\t\t\t\t\"value\": \"xh\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Yucatec Maya\",\n\t\t\t\t\t\t\t\t\t\"value\": \"yua\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Zapotec\",\n\t\t\t\t\t\t\t\t\t\"value\": \"zap\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Zarma\",\n\t\t\t\t\t\t\t\t\t\"value\": \"dje\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Zhuang\",\n\t\t\t\t\t\t\t\t\t\"value\": \"za\"\n\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t\t\"label\": \"Zulu\",\n\t\t\t\t\t\t\t\t\t\"value\": \"zu\"\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t],\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"placeholder\": \"\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"advanced_connection\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Connection\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"n_connection_retries\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Number of Retries:\",\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": null,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"retry_delay\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Seconds between Retry Attempts:\",\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"integer\": true,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 10,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"advanced_Processing\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Processing\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"n_threads\",\n\t\t\t\t\t\t\t\"type\": \"numstepper\",\n\t\t\t\t\t\t\t\"label\": \"Number of Threads:\",\n\t\t\t\t\t\t\t\"required\": true,\n\t\t\t\t\t\t\t\"integer\": false,\n\t\t\t\t\t\t\t\"min\": 1,\n\t\t\t\t\t\t\t\"max\": 64,\n\t\t\t\t\t\t\t\"stepsize\": 1\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"advanced_output\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Output\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"save_json_info_text\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Saves the raw OCR result as JSON files at the specified location.\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"save_files\",\n\t\t\t\t\t\t\t\"type\": \"checkbox\",\n\t\t\t\t\t\t\t\"label\": \"Save as JSON\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t},\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"json_output_folder\",\n\t\t\t\t\t\t\t\"type\": \"path\",\n\t\t\t\t\t\t\t\"label\": \"Output Folder:\",\n\t\t\t\t\t\t\t\"pathtype\": \"folder\",\n\t\t\t\t\t\t\t\"placeholder\": \"Folder to save the unparsed OCR results\",\n\t\t\t\t\t\t\t\"required\": false,\n\t\t\t\t\t\t\t\"visible\": \"$save_files\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t}\n\t\t\t]\n\t\t},\n\t\t{\n\t\t\t\"id\": \"pageAbout\",\n\t\t\t\"type\": \"page\",\n\t\t\t\"label\": \"About\",\n\t\t\t\"children\": [\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"textAbout\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"OCR - Azure AI Document Intelligence\\n=========================\\n\\nThis custom step uses the Azure Document Intelligence service to perform different types of OCR\\n\\nNOTE: The usage of this step requires an Azure AI Document Intelligence Resource. For more information, check the documentation below.\\n\\nSupported OCR types: \\n  * Text (word, line, paragraph, page)\\n  * Form (key-value pairs)\\n  * Query (specific keys)\\n  * Tables\\n\\nSupported file types:\\n  * Images: .png,  .jpg / .jpeg, .bmp, .tiff, .heif\\n  * Documents: .pdf\\n\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"sectionPrereqs\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Pre-requisites\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"textPrereqs\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"Tested on Viya version Stable 2024.1\\n\\nGeneral:\\n * Python >= 3.8\\n * Azure AI Document Intelligence Resource\\n\\nPython Packages:\\n * azure.ai.documentintelligence\\n * azure.core\\n * pandas\\n * numpy\\n\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"sectionDocumentation\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Documentation\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"textDocumentation\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"* Custom Step Repository & Documentation\\nhttps://github.com/sassoftware/sas-studio-custom-steps/tree/main/OCR%20-%20Azure%20Document%20Intelligence\\n\\n* Azure AI Document Intelligence documentation\\nhttps://learn.microsoft.com/en-US/azure/ai-services/document-intelligence/?view=doc-intel-4.0.0\\n\\n* Language Support\\nhttps://learn.microsoft.com/en-GB/azure/ai-services/document-intelligence/language-support-ocr?view=doc-intel-4.0.0&tabs=read-print%2Clayout-print%2Cgeneral\\n\\n* Pricing\\nhttps://azure.microsoft.com/en-us/pricing/details/ai-document-intelligence/#pricing\\n\\n* Data Privacy\\nhttps://learn.microsoft.com/en-us/legal/cognitive-services/document-intelligence/data-privacy-security\\n\\n* Install Local Container\\nhttps://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/containers/install-run?view=doc-intel-3.0\\n\\n* PROC PYTHON\\nhttps://go.documentation.sas.com/doc/en/pgmsascdc/default/proc/p1iycdzbxw2787n178ysea5ghk6l.htm\\n\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"sectionChangelog\",\n\t\t\t\t\t\"type\": \"section\",\n\t\t\t\t\t\"label\": \"Changelog\",\n\t\t\t\t\t\"open\": false,\n\t\t\t\t\t\"visible\": \"\",\n\t\t\t\t\t\"children\": [\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"id\": \"textChangelog\",\n\t\t\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\t\t\"text\": \"* Version: 1.0 (08JAN2024)\\n      - Initial version\",\n\t\t\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t\t\t}\n\t\t\t\t\t]\n\t\t\t\t},\n\t\t\t\t{\n\t\t\t\t\t\"id\": \"textAuthor\",\n\t\t\t\t\t\"type\": \"text\",\n\t\t\t\t\t\"text\": \"This custom step was created by <name> (<email>).\",\n\t\t\t\t\t\"visible\": \"\"\n\t\t\t\t}\n\t\t\t]\n\t\t}\n\t],\n\t\"syntaxversion\": \"1.3.0\",\n\t\"values\": {\n\t\t\"ocr_type\": {\n\t\t\t\"value\": \"text\",\n\t\t\t\"label\": \"Text\"\n\t\t},\n\t\t\"text_granularity\": {\n\t\t\t\"value\": \"paragraph\",\n\t\t\t\"label\": \"Paragraph\"\n\t\t},\n\t\t\"extract_pragraph_roles\": false,\n\t\t\"ocr_query_fields\": \"\",\n\t\t\"query_exclude_metadata\": true,\n\t\t\"table_output_format\": {\n\t\t\t\"value\": \"map\",\n\t\t\t\"label\": \"Mapping-Table\"\n\t\t},\n\t\t\"table_output_library\": \"WORK\",\n\t\t\"select_table\": false,\n\t\t\"tabel_selection_method\": {\n\t\t\t\"value\": \"index\",\n\t\t\t\"label\": \"Index\"\n\t\t},\n\t\t\"table_selection_idx\": 0,\n\t\t\"input_mode\": {\n\t\t\t\"value\": \"batch\",\n\t\t\t\"label\": \"A list of files (table)\"\n\t\t},\n\t\t\"input_type\": {\n\t\t\t\"value\": \"file\",\n\t\t\t\"label\": \"Local File(s)\"\n\t\t},\n\t\t\"input_table_name\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"path_column\": [],\n\t\t\"file_path\": \"\",\n\t\t\"file_url\": \"\",\n\t\t\"outputtable1\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"output_status_table\": false,\n\t\t\"outputtable2\": {\n\t\t\t\"library\": \"\",\n\t\t\t\"table\": \"\"\n\t\t},\n\t\t\"azure_endpoint\": \"https://your-resource.cognitiveservices.azure.com/\",\n\t\t\"azure_key\": \"SECRET_KEY\",\n\t\t\"local_ocr_endpoint\": \"https://localhost:5000\",\n\t\t\"local_ocr\": false,\n\t\t\"ocr_locale\": null,\n\t\t\"n_connection_retries\": 3,\n\t\t\"retry_delay\": 2,\n\t\t\"n_threads\": 16,\n\t\t\"save_files\": false,\n\t\t\"json_output_folder\": \"\"\n\t}\n}","flowMetadata":{"inputPorts":[{"name":"input_table_name","displayName":"input_table_name","description":"","minEntries":0,"maxEntries":1,"type":"table"}],"outputPorts":[{"name":"outputtable1","displayName":"outputtable1","description":"","minEntries":1,"maxEntries":1,"columnDelta":null,"type":"table"},{"name":"outputtable2","displayName":"outputtable2","description":"","minEntries":0,"maxEntries":1,"columnDelta":null,"type":"table"}]}}