{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import DocumentAnalysisFeature\n",
    "from azure.ai.documentintelligence.models._models import AnalyzeResult\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import functools\n",
    "import threading\n",
    "import json\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.environ.get('OCR_KEY')\n",
    "endpoint = os.environ.get('OCR_ENDPOINT')\n",
    "credential = AzureKeyCredential(key)\n",
    "document_intelligence_client = DocumentIntelligenceClient(endpoint, credential, api_version='2023-10-31-preview')\n",
    "doc_path ='../data/table-test-document.pdf'\n",
    "query_fields = ['first_name', 'city', 'state']\n",
    "\n",
    "with open(doc_path, \"rb\") as f:\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-layout\", \n",
    "        analyze_request=f,\n",
    "        content_type=\"application/octet-stream\", \n",
    "    )\n",
    "r_cloud = poller.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "service_url = 'http://localhost:5000/'\n",
    "\n",
    "# Define the URL and file path\n",
    "url = f\"{service_url}formrecognizer/documentModels/prebuilt-read:syncAnalyze?api-version=2022-08-31\"\n",
    "file_path = \"../data/handwritten-form.jpg\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    'accept': '*/*',\n",
    "    'Content-Type': 'application/octet-stream',\n",
    "}\n",
    "\n",
    "# Open the file and send the POST request\n",
    "with open(file_path, 'rb') as file:\n",
    "    response = requests.post(url, headers=headers, data=file)\n",
    "\n",
    "r_local = json.loads(response.text)\n",
    "r_local = r_local['analyzeResult']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud keys: dict_keys(['apiVersion', 'modelId', 'stringIndexType', 'content', 'pages', 'paragraphs', 'styles', 'contentFormat'])\n",
      "local keys: dict_keys(['apiVersion', 'modelId', 'stringIndexType', 'content', 'pages', 'paragraphs', 'styles', 'languages'])\n"
     ]
    }
   ],
   "source": [
    "print(f'cloud keys: {r_cloud.keys()}')\n",
    "print(f'local keys: {r_local.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud keys: dict_keys(['pageNumber', 'angle', 'width', 'height', 'unit', 'words', 'lines', 'spans'])\n",
      "local keys: dict_keys(['pageNumber', 'angle', 'width', 'height', 'unit', 'words', 'lines', 'spans', 'kind'])\n",
      "cloud keys: [{'confidence': 1, 'spans': [{'offset': 34, 'length': 6}, {'offset': 56, 'length': 20}, {'offset': 303, 'length': 32}, {'offset': 339, 'length': 2}, {'offset': 346, 'length': 3}, {'offset': 354, 'length': 3}, {'offset': 374, 'length': 5}, {'offset': 387, 'length': 6}, {'offset': 399, 'length': 4}, {'offset': 410, 'length': 5}, {'offset': 423, 'length': 6}, {'offset': 433, 'length': 2}, {'offset': 441, 'length': 4}, {'offset': 452, 'length': 5}, {'offset': 465, 'length': 6}, {'offset': 475, 'length': 2}, {'offset': 482, 'length': 3}, {'offset': 492, 'length': 5}, {'offset': 505, 'length': 9}, {'offset': 519, 'length': 3}, {'offset': 543, 'length': 6}, {'offset': 553, 'length': 2}, {'offset': 560, 'length': 3}, {'offset': 569, 'length': 4}, {'offset': 580, 'length': 5}, {'offset': 613, 'length': 28}, {'offset': 669, 'length': 26}, {'offset': 1075, 'length': 329}], 'isHandwritten': True}, {'confidence': 0.95, 'spans': [{'offset': 363, 'length': 4}], 'isHandwritten': True}, {'confidence': 0.8, 'spans': [{'offset': 528, 'length': 4}], 'isHandwritten': True}]\n",
      "local keys: [{'confidence': 1, 'spans': [{'offset': 34, 'length': 6}, {'offset': 56, 'length': 20}, {'offset': 303, 'length': 10}, {'offset': 317, 'length': 2}, {'offset': 329, 'length': 21}, {'offset': 364, 'length': 10}, {'offset': 380, 'length': 5}, {'offset': 395, 'length': 4}, {'offset': 406, 'length': 5}, {'offset': 419, 'length': 6}, {'offset': 429, 'length': 3}, {'offset': 444, 'length': 5}, {'offset': 457, 'length': 6}, {'offset': 467, 'length': 2}, {'offset': 474, 'length': 11}, {'offset': 492, 'length': 5}, {'offset': 505, 'length': 6}, {'offset': 519, 'length': 3}, {'offset': 533, 'length': 2}, {'offset': 543, 'length': 6}, {'offset': 553, 'length': 2}, {'offset': 565, 'length': 3}, {'offset': 575, 'length': 10}, {'offset': 613, 'length': 46}, {'offset': 687, 'length': 40}, {'offset': 1107, 'length': 328}], 'isHandwritten': True}, {'confidence': 0.95, 'spans': [{'offset': 375, 'length': 4}, {'offset': 528, 'length': 4}], 'isHandwritten': True}]\n"
     ]
    }
   ],
   "source": [
    "print(f'cloud keys: {r_cloud[\"pages\"][0].keys()}')\n",
    "print(f'local keys: {r_local[\"pages\"][0].keys()}')\n",
    "\n",
    "print(f'cloud keys: {r_cloud[\"styles\"]}')\n",
    "print(f'local keys: {r_local[\"styles\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud keys: dict_keys(['content', 'polygon', 'confidence', 'span'])\n",
      "local keys: dict_keys(['content', 'polygon', 'confidence', 'span'])\n"
     ]
    }
   ],
   "source": [
    "print(f'cloud keys: {r_cloud[\"pages\"][0][\"words\"][0].keys()}')\n",
    "print(f'local keys: {r_local[\"pages\"][0][\"words\"][0].keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud keys: [187, 15, 313, 15, 313, 34, 187, 33]\n",
      "local keys: [186, 13, 315, 14, 314, 37, 186, 35]\n",
      "cloud keys: HANDWRITING\n",
      "local keys: HANDWRITING\n",
      "cloud keys: 0.993\n",
      "local keys: 0.991\n",
      "cloud keys: {'offset': 0, 'length': 11}\n",
      "local keys: {'offset': 0, 'length': 11}\n"
     ]
    }
   ],
   "source": [
    "print(f'cloud keys: {r_cloud[\"pages\"][0][\"words\"][0][\"polygon\"]}')\n",
    "print(f'local keys: {r_local[\"pages\"][0][\"words\"][0][\"polygon\"]}')\n",
    "\n",
    "print(f'cloud keys: {r_cloud[\"pages\"][0][\"words\"][0][\"content\"]}')\n",
    "print(f'local keys: {r_local[\"pages\"][0][\"words\"][0][\"content\"]}')\n",
    "\n",
    "print(f'cloud keys: {r_cloud[\"pages\"][0][\"words\"][0][\"confidence\"]}')\n",
    "print(f'local keys: {r_local[\"pages\"][0][\"words\"][0][\"confidence\"]}')\n",
    "\n",
    "print(f'cloud keys: {r_cloud[\"pages\"][0][\"words\"][0][\"span\"]}')\n",
    "print(f'local keys: {r_local[\"pages\"][0][\"words\"][0][\"span\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Parsing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>text</th>\n",
       "      <th>role</th>\n",
       "      <th>bb_x1</th>\n",
       "      <th>bb_y1</th>\n",
       "      <th>bb_x2</th>\n",
       "      <th>bb_y2</th>\n",
       "      <th>bb_x3</th>\n",
       "      <th>bb_y3</th>\n",
       "      <th>bb_x4</th>\n",
       "      <th>bb_y4</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Liebe Handschrift,</td>\n",
       "      <td></td>\n",
       "      <td>89</td>\n",
       "      <td>41</td>\n",
       "      <td>339</td>\n",
       "      <td>36</td>\n",
       "      <td>340</td>\n",
       "      <td>78</td>\n",
       "      <td>90</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ich mag Dich nicht besonders. Jeder Drittkläss...</td>\n",
       "      <td></td>\n",
       "      <td>81</td>\n",
       "      <td>124</td>\n",
       "      <td>917</td>\n",
       "      <td>108</td>\n",
       "      <td>923</td>\n",
       "      <td>399</td>\n",
       "      <td>86</td>\n",
       "      <td>415</td>\n",
       "      <td>19</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Aber brauche ich Dich noch in einem Alltag, in...</td>\n",
       "      <td></td>\n",
       "      <td>87</td>\n",
       "      <td>423</td>\n",
       "      <td>946</td>\n",
       "      <td>438</td>\n",
       "      <td>942</td>\n",
       "      <td>667</td>\n",
       "      <td>83</td>\n",
       "      <td>652</td>\n",
       "      <td>392</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Du bildest unsere Persönlichkeit ab. Trotzdem ...</td>\n",
       "      <td></td>\n",
       "      <td>86</td>\n",
       "      <td>696</td>\n",
       "      <td>934</td>\n",
       "      <td>701</td>\n",
       "      <td>932</td>\n",
       "      <td>1056</td>\n",
       "      <td>84</td>\n",
       "      <td>1051</td>\n",
       "      <td>712</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Schriftliche grüße ,</td>\n",
       "      <td></td>\n",
       "      <td>94</td>\n",
       "      <td>1081</td>\n",
       "      <td>338</td>\n",
       "      <td>1087</td>\n",
       "      <td>337</td>\n",
       "      <td>1128</td>\n",
       "      <td>93</td>\n",
       "      <td>1122</td>\n",
       "      <td>1145</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page  paragraph                                               text role  \\\n",
       "0     1          0                                 Liebe Handschrift,        \n",
       "1     1          1  ich mag Dich nicht besonders. Jeder Drittkläss...        \n",
       "2     1          2  Aber brauche ich Dich noch in einem Alltag, in...        \n",
       "3     1          3  Du bildest unsere Persönlichkeit ab. Trotzdem ...        \n",
       "4     1          4                               Schriftliche grüße ,        \n",
       "\n",
       "   bb_x1  bb_y1  bb_x2  bb_y2  bb_x3  bb_y3  bb_x4  bb_y4  offset  length  \n",
       "0     89     41    339     36    340     78     90     83       0      18  \n",
       "1     81    124    917    108    923    399     86    415      19     372  \n",
       "2     87    423    946    438    942    667     83    652     392     319  \n",
       "3     86    696    934    701    932   1056     84   1051     712     432  \n",
       "4     94   1081    338   1087    337   1128     93   1122    1145      20  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_granularity = 'paragraph'\n",
    "model_id = 'prebuilt-read'\n",
    "\n",
    "def parse_ocr_result(result) -> pd.DataFrame:\n",
    "    text_granularity = 'PARAGRPAH'\n",
    "    model_id = 'prebuilt-layout'\n",
    "    parsed_result = None\n",
    "    # azure doesn't provide results on page level natively\n",
    "    level = text_granularity\n",
    "    if (level.upper() == 'PAGE'):\n",
    "        text_granularity = \"LINE\"\n",
    "    else:\n",
    "        text_granularity = level.upper()\n",
    "\n",
    "    for page in result['pages']:\n",
    "        try:\n",
    "            contains_handwriting = result.styles[0].is_handwritten\n",
    "        except:\n",
    "            contains_handwriting = False\n",
    "\n",
    "        ocr_data = []\n",
    "        \n",
    "        # to calculate the average confidence\n",
    "        if text_granularity != \"WORD\":\n",
    "            word_confidences = [word['confidence'] for word in page['words']]\n",
    "            total_confidence = sum(word_confidences)\n",
    "            total_words = len(word_confidences)\n",
    "            average_confidence = total_confidence / total_words if total_words > 0 else 0\n",
    "            \n",
    "        # extraction of (natively provided) results \n",
    "        if text_granularity == \"PARAGRPAH\":\n",
    "            for paragraph_idx, paragraph in enumerate(result['paragraphs']):\n",
    "                x1, y1, x2, y2, x3, y3, x4, y4 = paragraph['boundingRegions'][0]['polygon']\n",
    "\n",
    "                try: \n",
    "                    role = paragraph['role']\n",
    "                except:\n",
    "                    role = ''\n",
    "\n",
    "                paragrpah_info = {\n",
    "                    \"page\": paragraph['boundingRegions'][0]['pageNumber'],\n",
    "                    \"paragraph\": paragraph_idx,\n",
    "                    \"text\": paragraph['content'],\n",
    "                    \"role\": role,\n",
    "                    \"bb_x1\": x1,\n",
    "                    \"bb_y1\": y1,\n",
    "                    \"bb_x2\": x2,\n",
    "                    \"bb_y2\": y2,\n",
    "                    \"bb_x3\": x3,\n",
    "                    \"bb_y3\": y3,\n",
    "                    \"bb_x4\": x4,\n",
    "                    \"bb_y4\": y4,\n",
    "                    \"offset\": paragraph['spans'][0]['offset'],\n",
    "                    \"length\": paragraph['spans'][0]['length'],\n",
    "                    \n",
    "                }\n",
    "                \n",
    "                ocr_data.append(paragrpah_info)\n",
    "\n",
    "        elif text_granularity == \"LINE\":\n",
    "            for line_idx, line in enumerate(page['lines']):\n",
    "                x1, y1, x2, y2, x3, y3, x4, y4 = line['polygon']\n",
    "\n",
    "                line_info = {\n",
    "                    \"page\": page['pageNumber'],\n",
    "                    \"line\": line_idx,\n",
    "                    \"text\": line['content'],\n",
    "                    \"bb_x1\": x1,\n",
    "                    \"bb_y1\": y1,\n",
    "                    \"bb_x2\": x2,\n",
    "                    \"bb_y2\": y2,\n",
    "                    \"bb_x3\": x3,\n",
    "                    \"bb_y3\": y3,\n",
    "                    \"bb_x4\": x4,\n",
    "                    \"bb_y4\": y4,\n",
    "                    \"offset\": line['spans'][0]['offset'],\n",
    "                    \"length\": line['spans'][0]['length'],\n",
    "                }\n",
    "                \n",
    "                ocr_data.append(line_info)\n",
    "\n",
    "        elif text_granularity == \"WORD\":\n",
    "            for word in page.words:\n",
    "                x1, y1, x2, y2, x3, y3, x4, y4 = word['polygon']\n",
    "\n",
    "                word_info = {\n",
    "                    \"page\": page['pageNumber'],\n",
    "                    \"text\": word['content'],\n",
    "                    \"confidence\": word['confidence'],\n",
    "                    \"bb_x1\": x1,\n",
    "                    \"bb_y1\": y1,\n",
    "                    \"bb_x2\": x2,\n",
    "                    \"bb_y2\": y2,\n",
    "                    \"bb_x3\": x3,\n",
    "                    \"bb_y3\": y3,\n",
    "                    \"bb_x4\": x4,\n",
    "                    \"bb_y4\": y4,\n",
    "                    \"offset\": word['span']['offset'],\n",
    "                    \"length\": word['span']['length'],\n",
    "                    }\n",
    "                \n",
    "                ocr_data.append(word_info)\n",
    "        \n",
    "        df = pd.DataFrame(ocr_data)\n",
    "\n",
    "        # in case texts should be aggreagted on page level\n",
    "        if level.upper() == \"PAGE\":\n",
    "            ocr_data = []\n",
    "            page_info = {\n",
    "                    \"page\": page['pageNumber'],\n",
    "                    \"text\": \"\\n \".join(df['text']),\n",
    "                    \"avg_confidence\": average_confidence,\n",
    "                    \"contains_handwriting\": contains_handwriting,\n",
    "                    \"bb_x1\": df[\"bb_x1\"].min(),\n",
    "                    \"bb_y1\": df[\"bb_y1\"].min(),\n",
    "                    \"bb_x2\": df[\"bb_x2\"].max(),\n",
    "                    \"bb_y2\": df[\"bb_y2\"].min(),\n",
    "                    \"bb_x3\": df[\"bb_x3\"].max(),\n",
    "                    \"bb_y3\": df[\"bb_y3\"].max(),\n",
    "                    \"bb_x4\": df[\"bb_x4\"].min(),\n",
    "                    \"bb_x4\": df[\"bb_x4\"].max(),\n",
    "                    }\n",
    "            ocr_data.append(page_info)\n",
    "            \n",
    "            df = pd.DataFrame(ocr_data)\n",
    "\n",
    "    if model_id == 'prebuilt-read' and text_granularity.upper() == 'PARAGRAPH': # 'read' model doesn't provide semantic role, only 'layout' does\n",
    "        parsed_result = parsed_result.drop(columns=['role'])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = parse_ocr_result(r_cloud)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['spans', 'boundingRegions', 'content'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cloud['paragraphs'][3].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.993, 0.997, 0.986, 0.865, 0.984, 0.992, 0.984, 0.996, 0.994, 0.918, 0.981, 0.951, 0.97, 0.992, 0.992, 0.993, 0.994, 0.991, 0.991, 0.994, 0.997, 0.998, 0.998, 0.994, 0.993, 0.993, 0.998, 0.993, 0.994, 0.993, 0.997, 0.962, 0.993, 0.992, 0.998, 0.994, 0.994, 0.999, 0.999, 0.994, 0.991, 0.994, 0.988, 0.977, 0.989, 0.994, 0.992, 0.995, 0.951, 0.991, 0.945, 0.998, 0.231, 0.994, 0.924, 0.99, 0.981, 0.995, 0.852, 0.994, 0.99, 0.975, 0.951, 0.997, 0.967, 0.994, 0.974, 0.993, 0.999, 0.991, 0.995, 0.993, 0.997, 0.993, 0.994, 0.998, 0.996, 0.998, 0.997, 0.995, 0.99, 0.994, 0.918, 0.924, 0.998, 0.984, 0.988, 0.844, 0.972, 0.994, 0.994, 0.999, 0.999, 0.998, 0.988, 0.981, 0.963, 0.997, 0.994, 0.878, 0.154, 0.335, 0.859, 0.891, 0.99, 0.993, 0.998, 0.992, 0.988, 0.999, 0.998, 0.976, 0.988, 0.989, 0.998, 0.994, 0.998, 0.998, 0.994, 0.993, 0.99, 0.991, 0.997, 0.993, 0.991, 0.993, 0.989, 0.994, 0.993, 0.994, 0.993, 0.99, 0.959, 0.993, 0.997, 0.993, 0.989, 0.975, 0.994, 0.998, 0.992, 0.988, 0.998, 0.991, 0.998, 0.993, 0.998, 0.994, 0.991, 0.959, 0.998, 0.997, 0.932, 0.991, 0.994, 0.998, 0.993, 0.991, 0.993, 0.996, 0.998, 0.986, 0.993, 0.998, 0.985, 0.894, 0.995, 0.845, 0.99, 0.992, 0.717, 0.951, 0.957, 0.924, 0.994, 0.989, 0.985, 0.915, 0.79, 0.963, 0.918, 0.699, 0.961, 0.89, 0.974, 0.992, 0.993, 0.985, 0.951, 0.806, 0.992, 0.949, 0.852, 0.994, 0.918, 0.987, 0.924, 0.996, 0.601, 0.997, 0.937, 0.972, 0.997, 0.924, 0.827, 0.995, 0.99, 0.991, 0.957, 0.984, 0.938, 0.975, 0.994, 0.985, 0.982, 0.996, 0.924]\n"
     ]
    }
   ],
   "source": [
    "for page in r_cloud['pages']:\n",
    "\n",
    "    word_confidences = [word['confidence'] for word in page.words]\n",
    "    print(word_confidences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Value Parsing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ALEJANDRO'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cloud['keyValuePairs'][0]['value']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'offset': 161, 'length': 7}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cloud['documents'][0]['fields']['city']['spans'][0]['offset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>rowIndex</th>\n",
       "      <th>columnIndex</th>\n",
       "      <th>content</th>\n",
       "      <th>page</th>\n",
       "      <th>table_index</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y4</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>columnHeader</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>3.2688</td>\n",
       "      <td>1.9005</td>\n",
       "      <td>3.2688</td>\n",
       "      <td>1.9005</td>\n",
       "      <td>3.4957</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>3.4957</td>\n",
       "      <td>619.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>columnHeader</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>email</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9005</td>\n",
       "      <td>3.2688</td>\n",
       "      <td>3.6337</td>\n",
       "      <td>3.2688</td>\n",
       "      <td>3.6337</td>\n",
       "      <td>3.4957</td>\n",
       "      <td>1.9005</td>\n",
       "      <td>3.4957</td>\n",
       "      <td>624.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>columnHeader</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>phone</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6337</td>\n",
       "      <td>3.2688</td>\n",
       "      <td>5.1158</td>\n",
       "      <td>3.2688</td>\n",
       "      <td>5.1219</td>\n",
       "      <td>3.4957</td>\n",
       "      <td>3.6337</td>\n",
       "      <td>3.4957</td>\n",
       "      <td>630.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>columnHeader</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>birthdate</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.1158</td>\n",
       "      <td>3.2688</td>\n",
       "      <td>6.0222</td>\n",
       "      <td>3.2688</td>\n",
       "      <td>6.0222</td>\n",
       "      <td>3.4957</td>\n",
       "      <td>5.1219</td>\n",
       "      <td>3.4957</td>\n",
       "      <td>636.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>columnHeader</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>married</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0222</td>\n",
       "      <td>3.2688</td>\n",
       "      <td>6.9286</td>\n",
       "      <td>3.2688</td>\n",
       "      <td>6.9286</td>\n",
       "      <td>3.4957</td>\n",
       "      <td>6.0222</td>\n",
       "      <td>3.4957</td>\n",
       "      <td>646.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           kind  rowIndex  columnIndex    content  page  table_index      x1  \\\n",
       "0  columnHeader         0            0       name     1            0  1.0002   \n",
       "1  columnHeader         0            1      email     1            0  1.9005   \n",
       "2  columnHeader         0            2      phone     1            0  3.6337   \n",
       "3  columnHeader         0            3  birthdate     1            0  5.1158   \n",
       "4  columnHeader         0            4    married     1            0  6.0222   \n",
       "\n",
       "       y1      x2      y2      x3      y3      x4      y4  offset  length  \n",
       "0  3.2688  1.9005  3.2688  1.9005  3.4957  1.0002  3.4957   619.0     4.0  \n",
       "1  3.2688  3.6337  3.2688  3.6337  3.4957  1.9005  3.4957   624.0     5.0  \n",
       "2  3.2688  5.1158  3.2688  5.1219  3.4957  3.6337  3.4957   630.0     5.0  \n",
       "3  3.2688  6.0222  3.2688  6.0222  3.4957  5.1219  3.4957   636.0     9.0  \n",
       "4  3.2688  6.9286  3.2688  6.9286  3.4957  6.0222  3.4957   646.0     7.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_parsing(result) -> pd.DataFrame:\n",
    "        tables = []\n",
    "        table_output_format = 'map'\n",
    "        select_table = True\n",
    "        table_selection_method = 'index'\n",
    "        table_selection_idx = 0\n",
    "\n",
    "        # extract all table data\n",
    "        for index, table in enumerate(result['tables']):\n",
    "            if table_output_format.upper() == 'MAP':\n",
    "                dict = table.as_dict()\n",
    "                df = pd.DataFrame.from_dict(dict['cells'])\n",
    "\n",
    "                # extract page_number and polygon coordinates\n",
    "                df['page'] = df['boundingRegions'].apply(lambda x: x[0]['pageNumber'])\n",
    "                df['table_index'] = index\n",
    "                df['polygon'] = df['boundingRegions'].apply(lambda x: x[0]['polygon'])\n",
    "\n",
    "                # extract polygon coordinates\n",
    "                df['x1'] = df['polygon'].apply(lambda x: x[0])\n",
    "                df['y1'] = df['polygon'].apply(lambda x: x[1])\n",
    "                df['x2'] = df['polygon'].apply(lambda x: x[2])\n",
    "                df['y2'] = df['polygon'].apply(lambda x: x[3])\n",
    "                df['x3'] = df['polygon'].apply(lambda x: x[4])\n",
    "                df['y3'] = df['polygon'].apply(lambda x: x[5])\n",
    "                df['x4'] = df['polygon'].apply(lambda x: x[6])\n",
    "                df['y4'] = df['polygon'].apply(lambda x: x[7])\n",
    "\n",
    "                # extract offset and length\n",
    "                df['offset'] = df['spans'].apply(lambda x: int(x[0]['offset']) if x else None)\n",
    "                df['length'] = df['spans'].apply(lambda x: int(x[0]['length']) if x else None)\n",
    "\n",
    "                # drop unnecessary columns\n",
    "                df.drop(columns=['boundingRegions','spans', 'polygon'], inplace=True)\n",
    "\n",
    "                table_info = {\n",
    "                    'table_index': index,\n",
    "                    'row_count': table['rowCount'],\n",
    "                    'column_count': table['columnCount'],\n",
    "                    'cell_count': table['rowCount']*table['columnCount'],\n",
    "                    'table': df\n",
    "                }\n",
    "\n",
    "                tables.append(table_info)\n",
    "\n",
    "        # select specific table (optional)\n",
    "        if select_table:\n",
    "            if table_selection_method.upper() == 'INDEX':\n",
    "                parsed_result = tables[table_selection_idx]['table']\n",
    "            elif table_selection_method.upper() == 'SIZE':\n",
    "                # Find the entry with the highest cell_count using max function\n",
    "                table_most_cells = max(tables, key=lambda x: x['cell_count'], default=None)\n",
    "                parsed_result = table_most_cells['table'] if table_most_cells else None\n",
    "\n",
    "        else:\n",
    "            # combine all extracted tables (only works for output type 'map')\n",
    "            parsed_result = pd.concat([table['table'] for table in tables], ignore_index=True)\n",
    "\n",
    "        return parsed_result\n",
    "\n",
    "df = map_parsing(r_cloud)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save table tbl_fc3b101424e189530ff9d3dd99042 to caslib test\n",
      "Save table tbl_38b618abc421baeed61c929b1e343 to caslib test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>out_library</th>\n",
       "      <th>table_reference</th>\n",
       "      <th>row_count</th>\n",
       "      <th>column_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>tbl_fc3b101424e189530ff9d3dd99042</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>tbl_38b618abc421baeed61c929b1e343</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  out_library                    table_reference  row_count  column_count\n",
       "0        test  tbl_fc3b101424e189530ff9d3dd99042          5             5\n",
       "1        test  tbl_38b618abc421baeed61c929b1e343          5             3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def result_to_dfs(result) -> list:\n",
    "        tables = []\n",
    "        for table in result.tables:\n",
    "            table_df = pd.DataFrame(columns=range(table['columnCount']), index=range(table['rowCount']))\n",
    "\n",
    "            for cell in table['cells']:\n",
    "                table_df.iloc[cell['rowIndex'], cell['columnIndex']] = cell['content']\n",
    "\n",
    "            # use the first row as column names\n",
    "            table_df.columns = table_df.iloc[0]\n",
    "            table_df = table_df[1:]\n",
    "            \n",
    "            tables.append(table_df)\n",
    "        return tables\n",
    "\n",
    "def reference_parsing(result) -> pd.DataFrame: # TODO\n",
    "        tables = result_to_dfs(result)\n",
    "        table_output_library = 'test'\n",
    "        table_info = []\n",
    "\n",
    "        for table in tables:\n",
    "            reference = uuid.uuid4()\n",
    "            reference = re.sub(r'^\\w{3}', 'tbl_', str(reference))\n",
    "            reference = reference.replace('-', '')\n",
    "\n",
    "            # save table to caslib\n",
    "            try: \n",
    "                print(f'Save table {reference} to caslib {table_output_library}')\n",
    "            except Exception as e:\n",
    "                print(f'Failed to save table {reference} to caslib {table_output_library}')\n",
    "                raise e\n",
    "            \n",
    "            table_info.append({\n",
    "                'out_library': table_output_library,\n",
    "                'table_reference': reference,\n",
    "                'row_count': table.shape[0],\n",
    "                'column_count': table.shape[1],\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(table_info)\n",
    "\n",
    "\n",
    "df = reference_parsing(r_cloud)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cloud['tables'][0].get('columnCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>birthdate</th>\n",
       "      <th>married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bernd</td>\n",
       "      <td>12.05.92</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Klara</td>\n",
       "      <td>13.05.92</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Silvi</td>\n",
       "      <td>14.05.92</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cho</td>\n",
       "      <td>15.05.92</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clark</td>\n",
       "      <td>16.05.92</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0   name birthdate married\n",
       "1  Bernd  12.05.92     yes\n",
       "2  Klara  13.05.92     yes\n",
       "3  Silvi  14.05.92     yes\n",
       "4    Cho  15.05.92     yes\n",
       "5  Clark  16.05.92     yes"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def table_parsing(result) -> pd.DataFrame: #TODO\n",
    "        tables = result_to_dfs(result)\n",
    "        select_table = True\n",
    "        table_selection_idx = 1\n",
    "        table_selection_method = 'index'\n",
    "\n",
    "        # select specific table \n",
    "        if select_table:\n",
    "            if table_selection_method.upper() == 'INDEX': # Table with index == table_selection_idx\n",
    "                parsed_result = tables[table_selection_idx]\n",
    "            elif table_selection_method.upper() == 'SIZE': # Table with most cells\n",
    "                table_most_cells = max(tables, key=lambda x: x.size, default=None)\n",
    "                try:\n",
    "                    parsed_result = table_most_cells\n",
    "                except:\n",
    "                    parsed_result = None\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f'Invalid table selection method: {table_selection_method}')\n",
    "\n",
    "        return parsed_result\n",
    "\n",
    "\n",
    "df = table_parsing(r_cloud)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rowCount', 'columnCount', 'cells', 'boundingRegions', 'spans'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cloud['tables'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
